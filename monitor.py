from scapy.all import *
import os
from netfilterqueue import NetfilterQueue
from sklearn.feature_extraction.text import TfidfVectorizer
import os
from sklearn.cross_validation import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier
from sklearn.kernel_approximation import RBFSampler
from sklearn.externals import joblib
from sklearn import metrics
import urllib.parse
import matplotlib.pyplot as plt
import cProfile
from pathlib import Path

os.system('iptables -I OUTPUT -j NFQUEUE --queue-bypass')
os.system('iptables -I INPUT -j NFQUEUE --queue-bypass')
os.system('iptables -I FORWARD -j NFQUEUE --queue-bypass')


def loadFile(name):
    directory = str(os.getcwd())
    filepath = os.path.join(directory, name)
    with open(filepath, 'r') as f:
        data = f.readlines()
    data = list(set(data))
    result = []
    for d in data:
        d = str(urllib.parse.unquote(
            d))  #converting url encoded data to simple string
        result.append(d)
    return result


badQueries = loadFile('./badpayloads')
validQueries = loadFile('./goodpayloads')

badQueries = list(set(badQueries))
validQueries = list(set(validQueries))
allQueries = badQueries + validQueries
yBad = [1 for i in range(0, len(badQueries))]
yGood = [0 for i in range(0, len(validQueries))]
y = yBad + yGood
queries = allQueries

vectorizer = TfidfVectorizer(
    min_df=0.0, analyzer="char", sublinear_tf=True, ngram_range=(1, 3))
X = vectorizer.fit_transform(queries)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.1, random_state=42)
badCount = len(badQueries)
validCount = len(validQueries)

lgs = LogisticRegression(
    class_weight={
        1: 2 * validCount / badCount,
        0: 1.0
    }, n_jobs=4)
lgs.fit(X_train, y_train)

predicted = lgs.predict(X_test)
fpr, tpr, _ = metrics.roc_curve(y_test, (lgs.predict_proba(X_test)[:, 1]))
auc = metrics.auc(fpr, tpr)

print("Bad samples: %d" % badCount)
print("Good samples: %d" % validCount)
print("Baseline Constant negative: %.6f" % (validCount /
                                            (validCount + badCount)))
print("------------")
print("Accuracy: %f" % lgs.score(X_test, y_test))
print("Precision: %f" % metrics.precision_score(y_test, predicted))
print("Recall: %f" % metrics.recall_score(y_test, predicted))
print("F1-Score: %f" % metrics.f1_score(y_test, predicted))
print("AUC: %f" % auc)


def check_dns_tunnel(packet):
    return
    if packet[DNS].rcode != 0 and packet[DNS].rcode != 3:
        return
    if DNSRR in packet:
        if 12 == packet[DNSRR].type or 33 == packet[DNSRR].type:
            return
        if packet[DNSRR].rdlen < 100:
            return
        print(packet)
    elif DNSQR in packet:
        if 12 == packet[DNSQR].qtype or 33 == packet[DNSQR].qtype:
            return
        #print(packet[DNSQR])


def check_dhcp_wpad(packet):
    print("to do")
    #print(packet[DHCP].show())


def check_exploit_attempt():
    print("to do")


def callback(pkt):
    try:
        packet = IP(pkt.get_payload())
        if UDP in packet:
            if DNS in packet[UDP]:
                check_dns_tunnel(packet)
            elif DHCP in packet[UDP]:
                check_dhcp_wpad(packet)
        elif TCP in packet:
            if DNS in packet[TCP]:
                check_dns_tunnel(packet)
            payload = packet[Raw].load.decode("utf-8")
            if packet.haslayer(Raw) and "GET" in packet[Raw].load.decode(
                    "utf-8"):
                fields = packet[Raw].load.decode("utf-8").split("\r\n")
                for field in fields:
                    if "GET" in field:
                        query = field.split(" ")[1]
                        continue
                    if "Host" in field:
                        host = field.split(":")[1].strip()
                        continue
                url = host + query
                X_predict = [query]
                X_predict = vectorizer.transform(X_predict)
                y_Predict = lgs.predict(X_predict)
                print(url + " " + str(y_Predict[0]))
        pkt.accept()
    except KeyboardInterrupt:
        pkt.accept()
        raise
    except Exception:
        pkt.accept()


def main():
    nfqueue = NetfilterQueue()
    nfqueue.bind(0, callback)
    try:
        nfqueue.run()
    except KeyboardInterrupt:
        nfqueue.unbind()
        os.system('iptables -F')
        os.system('iptables -X')
        sys.exit('losing...')


cProfile.run('main()')
